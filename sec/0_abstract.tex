\begin{abstract}
Convolutional Neural Networks (CNNs) have demonstrated remarkable performance in various computer vision tasks, attributed to their ability to learn hierarchical features and their translation equivariance. However, standard CNNs lack rotational invariance, leading to performance degradation with rotated objects. While Rotation-Invariant Convolutional Neural Networks (RIC-CNNs) address this, they exhibit limitations in discriminating between rotationally symmetric objects with distinct meanings at different orientations (e.g., '6' and '9'). This limitation, as noted in Mo et al. (2022), can hinder performance in scenarios where such distinctions are crucial. In this work, we explore combining the rotational invariance of RIC-CNNs with the discriminative power of standard CNNs.  Specifically, we investigate several approaches to integrate these architectures, aiming to achieve robust performance on both rotated and non-rotated image datasets. We evaluate our approaches on the MNIST and Traffic Signs datasets, demonstrating improved performance and robustness compared to using either CNNs or RIC-CNNs alone.
\end{abstract}